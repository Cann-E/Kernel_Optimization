# ğŸš€ Kernel_Optimization

A CUDA-based project focused on optimizing matrix transpose operations. The goal is to compare naive, shared memory, and high-performance GPU kernel implementations for matrix transposition and measure their speedup over CPU and baseline GPU methods.

---

## ğŸ§  Description

This project implements multiple matrix transpose kernels in CUDA. Starting from a naive implementation, it introduces shared memory usage and culminates in a fully optimized version. Performance is measured across multiple matrix sizes (512x512 to 4096x4096). The optimizations focus on reducing global memory latency, maximizing coalesced access, and improving instruction throughput using GPU-specific techniques.

---

## ğŸ”§ Tech Stack

- CUDA
- C++
- NVCC
- Makefile build system

---

## âœ¨ Key Features

- âœ… Naive GPU transpose kernel for baseline comparison  
- âœ… Shared memory-based transpose kernel  
- âœ… Fully optimized transpose kernel using:
  - Instruction-level parallelism (ILP)  
  - Loop unrolling  
  - Vectorized memory access  
  - Coalesced reads/writes  
- âœ… CPU-based transpose for reference  
- âœ… Performance output in milliseconds across matrix sizes

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ Makefile                  # Builds the project
â”œâ”€â”€ transpose                 # Final executable
â”œâ”€â”€ transpose_host.cpp        # CPU baseline transpose
â”œâ”€â”€ transpose_device.cu       # CUDA kernels (naive, shmem, optimized)
â”œâ”€â”€ transpose_device.cuh      # Kernel headers
â”œâ”€â”€ ta_utilities.cpp/.hpp     # Utility code
â”œâ”€â”€ README                    # Assignment spec (copied from instructions)
```

---

## ğŸ› ï¸ Setup & Usage

### âœ… Requirements

- CUDA Toolkit 12.x or later
- NVIDIA GPU with Compute Capability 3.5+
- Linux/macOS environment with `make`

### âš™ï¸ Build

```bash
make
```

### â–¶ï¸ Run

```bash
./transpose
```

### ğŸ’¡ Example Output

```
Size 512 naive CPU: 0.850624 ms
Size 512 GPU memcpy: 0.043104 ms
Size 512 naive GPU: 0.143360 ms
Size 512 shmem GPU: 0.027648 ms
Size 512 optimal GPU: 0.023392 ms
```

---

## ğŸ“¸ Output

Command-line output with timings for each kernel version across various matrix sizes. Results include GPU memcpy overhead, CPU vs GPU baseline comparisons, and optimized execution time.

---

## ğŸ‘¥ Contributors

- Can Ercan (@cann-e)

---

